import scrapy


class DivannewparsSpider(scrapy.Spider):
    name = "divannewpars"
    allowed_domains = ["https://www.divan.ru"]
    # start_urls - это та ссылка, от которой начинается парсинг
    start_urls = ["https://www.divan.ru/category/divany-i-kresla"]

    def parse(self, response):
        # divans = response.css('div._Ud0k U4KZV')
        divans = response.css('div._Ud0k')
        # Настраиваем работу с каждым отдельным диваном в списке
        for divan in divans:
            # Используем новый для нас оператор "yield", который помогает обрабатывать одно отдельное действие
            # С его помощью мы можем управлять потоком выполнения, останавливать и возобновлять работу парсера
            # С другими операторами мы такого делать не можем
            yield {
                # Ссылки и теги получаем с помощью консоли на сайте
                # Создаём словарик названий, используем поиск по диву (div), а внутри дива — по тегу span
                # Двойное двоеточие :: означает псевдоэлемент, в данном случае псевдокласс
                # Берём текст из данного тэга span, который находится внутри тэга div с классом lsooF
                # Используем get(), чтобы взять только первый элемент
                'name': divan.css('div.lsooF span::text').get(),
                # Создаём словарик цен, используем поиск по диву, а внутри дива — по тегу span
                'price': divan.css('div.pY3d2 span::text').get(),
                # Создаём словарик ссылок, используем поиск по тегу "a", а внутри тега — по атрибуту
                # Атрибуты — это настройки тегов; берём атрибут 'href' (ссылка)
                'url': divan.css('a').attrib['href']
            }
